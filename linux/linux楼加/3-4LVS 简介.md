# LVS 简介

## 1. 实验介绍

### 1.1 实验内容

随着网络的发达，高频的服务访问，造成服务器的压力成几何倍数的增长，为了能够给用户提供更好、更高质量的用户体验，提出了集群、高可用的概念。本节实验便带领大家了解什么是集群、什么是高可用，为什么需要，以及如何实现。

### 1.2 实验涉及的知识点

- 负载均衡的产生
- 负载均衡的方式
- LVS 的特点
- LVS 的组成部分
- LVS 的实现原理

### 1.3 推荐阅读

本实验文档中，部分内容节选于章文嵩博士发表的关于 LVS 的相关博文，

其博文最早发表在 IBM developerWorks，可点击[此处](https://www.ibm.com/developerworks/cn/linux/cluster/lvs/part1/index.html)查看博文详情。 

## 2. 负载均衡的产生

随着网络的飞速发展，我们服务被访问的次数成几何倍数的增长，例如微博中一个热点就可以造成上亿次甚至几十亿访问，无时无刻都有人在用着百度的搜索等等，这样同时高频的访问给我们的服务器带来非常大的压力，轻则无法及时处理用户的请求，重则服务崩溃，用户无法访问。

所以对于这样的访问环境，为了让用户有更好的用户体验，我们会有这样的需求：

- 可伸缩性（Scalability）：当服务的负载增长时，系统能被扩展来满足需求，从而实现不降低服务质量。
- 高可用性（Availability）：尽管部分硬件和软件会发生故障，整个系统的服务必须是每天 24 小时可用。
- 可管理性（Manageability）：整个系统可能在在机器数量上很大，但应该容易管理。
- 价格有效性（Cost-effectiveness）：整个系统实现是经济的、易支付的。

这样的需求促使了服务器集群的产生，单台的服务器一台并不能满足我的需求，高配置成本过高，由此我们便使用多台稍低配置服务器同时为我们提供服务，而这样的多台服务器我们称之为服务器集群。

为了更好的管理集群，更好的提供服务，由此出现了负载均衡技术，通过负载均衡技术来管理多台提供服务的机器（集群），相较于之前有这样的一些优势：

- 多台低配置的机器降低了成本的支出（因为越高端的服务器价格越高昂），从而做到价格有效性；
- 多台机器提供服务，在其中某一台出故障的时候并不会影响其他机器提供服务，客户访问也不会感知到某个节点的服务故障，从而做到高可用性；
- 多台机器提供服务，在业务增长时只需添加机器即可做到扩展，在业务回落时也能及时回收，从而做到可伸缩性；
- 多台机器由负载设备或软件管理，在添加、减少时容易控制，达到可管理性能；

![Load_Balance](https://dn-anything-about-doc.qbox.me/document-uid113508labid1timestamp1473132683636.png/wm)

## 3. 负载均衡的方式

上文所述负载均衡就是由两台或者以上的服务器为我们提供服务，我们将来自客户端的请求靠某种算法尽量平均分摊到这些集群中，从而避免一台服务器因为负载太高而出现故障，同时能够在某台服务器故障时其他服务继续提供服务，让用户无感知。

而从早期到现在负载均衡方式有这样的两种：

- 硬件负载均衡
- 软件负载均衡

其中硬件负载均衡解决方案是直接在服务器和外部网络间安装负载均衡设备，由专门的硬件设备完成专门的任务，独立于操作系统，整体性能略高于软件负载均衡的实现，但是相对来说成本较高。常用的负载均衡器有这样一些：

- F5 BIG-IP
- Citrix Netscaler
- Alteon ACEDirector
- Cisco LocalDirector

![F5-Big-IP](https://dn-anything-about-doc.qbox.me/document-uid113508labid1timestamp1473134438124.png/wm) 

而更加广泛的则是使用软件的方式来实现负载均衡，实现效果不错，并且不需要成本。其中常用的方式有：

- LVS
- Nginx
- Maglev

其中的 LVS 是章文嵩博士在 1998 年 5 月成立了 Linux Virtual Server（LVS） 的自由软件项目，进行 Linux 服务器集群的开发工作，并在网站上发布第一个版本源程序。并且在 Linux2.4 以后的内核版本中，直接将 LVS 加入内核中，不用再重新自行编译进内核。

## 4. LVS 的特点

LVS 能够被广泛的运用是因为其有这样的一些特点：

在功能上：

- 其中的组件 IPVS 软件实现三种 IP 负载均衡技术和八种连接调度算法。在 IPVS 内部实现上，采用了高效的 Hash 函数和垃圾回收机制，能正确处理所调度报文相关的 ICMP 消息。

- 其中 KTCPVS 软件实现基于内容请求分发的应用层交换，它也是在 Linux 内核中实现。有相关的集群管理软件对资源进行监测，能及时将故障屏蔽，实现系统的高可用性。主、从调度器能周期性地进行状态同步，从而实现更高的可用性。

![LVS_framework](https://dn-anything-about-doc.qbox.me/document-uid113508labid1timestamp1473130913314.png/wm)

在适用性上：

- 后端服务器可运行任何支持 TCP/IP 的操作系统，包括 Linux，各种Unix（如 FreeBSD、Sun Solaris、HP Unix 等），Mac/OS 和Windows NT/2000 等。

- 负载调度器能够支持绝大多数的 TCP 和 UDP 协议：

| 协 议 | 内 容                                                        |
| ----- | ------------------------------------------------------------ |
| TCP   | HTTP，FTP，PROXY，SMTP，POP3，IMAP4，DNS，LDAP，HTTPS，SSMTP 等 |
| UDP   | DNS，NTP，ICP，视频、音频流播放协议等                        |

在性能上：

- LVS 服务器集群系统具有良好的伸缩性，可支持几百万甚至更高的并发连接。

## 5. LVS 的组成部分

考虑到系统的透明性、伸缩性以及高可用性和易管理性，使用 LVS 搭建的服务器集群系统一般采用三层结构：

* 最前端的负载均衡层(Load Balancer)
* 中间的服务器池层(Server pool)
* 最后端的数据共享储存层(Share Storage)。

整个服务器集群的结构对用户来说是透明的，并且无需修改客户端和服务端程序，用户只需直接使用服务即可：

![](https://dn-anything-about-doc.qbox.me/document-uid113508labid1timestamp1473132412228.png/wm)

各个层次的作用说明：

* **负载调度器层（load balancer**）：它是整个集群对外面的前端机，负责将客户端的请求发送到一组后端服务器上执行，负载调度层通常由一台或者多台负载调度器(Director Server)组成，LVS 模块需要安装在每个负载调度器上。
* **服务器池层（Server pool）**：是一组真正处理客户请求的服务器，执行的服务为 WEB、MAIL、FTP 和 DNS 等。每个真实服务器(Real Server)之前通过高速的 LAN 或分布在各地的 WAL 相连接。
* **数据共享储存层(Share Storage)**：它为服务器池提供一个共享的存储区，这样容易使得服务器池中的主机拥有相同的信息与配置，从而便于共同提供服务。

调度器是服务器集群系统的唯一入口点（Single Entry Point），它可以采用 IP 负载均衡技术、基于内容请求分发技术或者两者相结合。在 IP 负载均衡技术中，需要服务器池拥有相同的内容提供相同的服务。

> 由于 LVS 只是对 IP 进行处理，对数据包的内容并不关心，所以称为基于 IP 的负载均衡技术。

服务器池的结点数目是可变的。当整个系统收到的负载超过目前所有结点的处理能力时，可以在服务器池中增加服务器来满足不断增长的请求负载。对大多数网络服务来说，请求间不存在很强的相关性，请求可以在不同的结点上并行执行，所以整个系统的性能基本上可以随着服务器池的结点数目增加而线性增长。

共享存储通常是数据库、网络文件系统或者分布式文件系统。服务器结点需要动态更新的数据一般存储在数据库系统中，同时数据库会保证并发访问时数据的一致性。

## 6. LVS 的实现原理

在上文中我们多次提到 LVS 是基于 IP 负载均衡的技术，那什么是基于 IP 负载均衡呢？

我们通过这样的流程来理解：

LVS 的 IP 负载均衡技术是通过 IPVS 模块实现，IPVS 也是 LVS 集群系统的核心软件。它安装在负载调度器（Director Server）上，同时在负载均衡器上虚拟出一个 IP 地址，用户只能通过访问这个 IP 地址来获取服务。这个虚拟 IP 地址也称为 VIP（Virtual IP Address）。

用户通过虚拟 IP 地址（Virtual IP Address）访问服务时，访问请求的报文会到达负载调度器，由它进行负载均衡调度，从一组真实服务器选出一个，将报文的目标地址 Virtual IP Address 改写成选定服务器的地址，最后将报文发送给选定的服务器。

真实服务器会根据不同的模式相应该请求数据包。

从底层来说 LVS 便是通过修改数据包中的 IP 地址来做数据包的分发。这就是基于 IP 地址的负载均衡。

而对于不同的 IP 负载均衡技术，数据包的修改方式也不相同，服务器的响应方式也不同，IP 负载均衡技术分为三种：

- 通过 NAT 实现虚拟服务器（VS/NAT）
- 通过 IP 隧道实现虚拟服务器（VS/TUN）
- 通过直接路由实现虚拟服务器（VS/DR）

在选择真实服务器时有 8 中调度算法的选择：

- 轮询（Round Robin）
- 加权轮询（Weighted Round Robin）
- 最少链接（Least Connections）
- 加权最少链接（Weighted Least Connections）
- 基于局部性的最少链接（Locality-Based Least Connections）
- 带复制的基于局部性最少链接（Locality-Based Least Connections with Replication）
- 目标地址散列（Destination Hashing）
- 源地址散列（Source Hashing）

> 这里并不会对算法做过多的介绍，若想了解 8 中调度算法的相关作用与实现方式的同学可以访问官方文档，有详细的介绍。

为了了解如何配置负载均衡，我们需要对三种技术做更深入的了解：

1.VS/NAT 实现虚拟服务器

由于 IPv4 中 IP 地址空间的日益紧张和安全方面的原因，很多网络使用保留 IP 地址（10.0.0.0/255.0.0.0、 172.16.0.0/255.128.0.0和192.168.0.0/255.255.0.0）。这些地址不在 Internet 上使用，而是专门为内部网络预留的。

当内部网络中的主机要访问 Internet 或被 Internet 访问时，就需要采用网络地址转换（Network Address Translation, 以下简称 NAT），将内部地址转化为 Internet 上可用的外部地址。

NAT 的工作原理是报文头（目标地址、源地址和端口等）被正确改写后，客户相信它们连接一个 IP 地址，而不同 IP 地址的服务器组也认为它们是与客户直接相连的。由此，可以用 NAT 方法将不同 IP 地址的并行网络服务变成在一个IP地址上的一个虚拟服务。

下图为 VS/NAT 实现虚拟服务器的体系结构：

![](https://dn-anything-about-doc.qbox.me/document-uid113508labid1timestamp1473140003462.png/wm)

**主要工作流程：**

    1. 当用户通过虚拟 IP 地址（VIP，可通过公网访问）访问网络服务时，请求到达调度器，调度器将根据调度算法动态的从后端服务器池中选取一台真实服务器（Real Server）负责响应，同时调度器将请求报文的目标地址（VIP）改写为 Real Server 的 IP 地址，将报文的目标端口改写为 Real Server 相应的端口，最后将报文发送给选定的 Real Server，同时调度器在连接 Hash 表中记录这个连接记录。
    2. Real Server 收到数据并处理数据后，将响应的报文发送给调度器，调度器根据连接 Hash 表中的记录，将响应报文的源 IP 地址和源端口改写为虚拟IP（VIP）和调度器的相应端口。
    3. 最后，调度器将响应数据发送给用户，完成这个负载均衡过程。

  在 NAT 模式下，用户请求和响应报文都会经过负载调度器，并且被修改 IP 地址和端口。整个过程中，用户只能看到是 VIP 所在服务器提供的服务，而后端服务器集群结构对用户是透明的。

**应用实例：**

服务器集群拓扑结构：

![](https://dn-simplecloud.qbox.me/1135081473145279226-wm)

- 用户端：IP：**203.100.106.1**
- 负载调度器（Load Balancer）：VIP（即公网 IP）：**205.100.106.2**，内网 IP：**172.16.1.2**。
- 后端服务器池（Real Servers）：
  + 内网 IP：**172.16.1.3**（Real Server1）
  + 内网 IP：**172.16.1.4**（Real Server2）

所有用户端请求都将通过 VIP 到达负载均衡器 **Load Balancer**（下文简称 LB），LB 通过负载均衡算法将请求转发到后端一台真实服务器 **Real Server**（下文简称 RS）。

传输协议，IP 及端口一览表：

| Protocol | Virtual IP Address | Port | Real IP Address | Port |
| -------- | ------------------ | ---- | --------------- | ---- |
| TCP      | 205.100.106.2      | 80   | 172.16.1.3      | 80   |
|          |                    |      | 172.16.1.4      | 8080 |
| TCP      | 205.100.106.2      | 21   | 172.16.1.3      | 21   |

整个负载均衡过程中，报文 IP 地址及端口变化情况如下：

**用户端 —> 负载均衡器：请求报文中源 IP 地址与目标 IP 地址（虚拟服务器 VIP 地址）：**

| SOURCE             | DEST             |
| ------------------ | ---------------- |
| 203.100.106.1:3456 | 205.100.106.2:80 |

**负载调度器 —> 后端真实服务器：调度器根据算法选择一台后端真实服务器，这里以  Real Server2 示例，请求报文目标 IP 地址被改写为 Real Server2 所在 IP：**

| SOURCE             | DEST            |
| ------------------ | --------------- |
| 203.100.106.1:3456 | 172.16.1.4:8080 |

**后端真实服务器 —> 负载调度器：响应报文再次经过调度器：**

| SOURCE          | DEST             |
| --------------- | ---------------- |
| 172.16.1.4:8080 | 205.100.106.2:80 |

**负载调度器 —> 用户端：虚拟服务器响应用户请求，响应报文源 IP 地址被改写为虚拟服务器的 VIP 地址：**

| SOURCE           | DEST               |
| ---------------- | ------------------ |
| 205.100.106.2:80 | 203.100.106.1:3456 |

整个过程概括为： 

**用户请求 —> 虚拟服务器（负载均衡调度器） —> 后端服务器 —> 负载调度器（虚拟服务器） —> 用户响应**

使用 NAT 模式做负载均衡时，需要有以下几点**注意事项：**

- **集群节点，也就是 Real Server 与 Load Balacer 必须在同一个 IP 网络中**
- **Load Balancer 位于 Real Server 与用户端之间，处理进出的所有通信**
- **RIP 通常是私有地址，仅用于各个集群节点之间的通信。**
- **Real Server 的网关必须指向 Load Balancer**
- **支持端口映射：也就是 Real Server 的端口可以自己设定，不必与 Load Balancer 保持一样**

这种负载均衡模式的缺点也很明显，所有进出的报文都要经过负载均衡器（Director Server），当用户请求很多时，调度器的处理能力将会成为整个系统的瓶颈。一般支持的真实服务器数目在 10 台至 20 台左右。

2.VS/DR 实现虚拟服务器

在VS/NAT 的集群系统中，请求和响应的数据报文都需要通过负载调度器，当真实服务器的数目在10台和20台之间时，负载调度器将成为整个集群系统的新瓶颈。大多数 Internet服务都有这样的特点：请求报文较短而响应报文往往包含大量的数据。

既然同时处理进出报文会大大的影响效率，增加机器的负载，那么若是仅仅处理进来的报文，即在负载调度器中只负责调度请求,而出去的报文由 Real Server 直接发给客户端这样岂不是高效许多。

VS/DR（Virtual Server via Direct Routing）利用大多数 Internet 服务的非对称特点，负载调度器中只负责调度请求，而服务器直接将响应返回给客户，可以极大地提高整个集群系统的吞吐量。

VS/DR 实现的虚拟服务器是这样的一个结构，主要经过这样的一些步骤：

![DR-sturct](https://dn-simplecloud.qbox.me/1135081473148031595-wm)

1. 客户端通过 Internet 向服务器发起请求，而请求的 IP 地址指向的是调度器上对外公布的 IP 地址；
2. 请求报文到达调度器（Load Balancer），调度器根据各个服务器的负载情况，动态地选择一台服务器，不修改也不封装 IP 报文，而是将数据帧的 MAC 地址改为选出服务器的 MAC 地址，再将修改后 的数据帧在与服务器组的局域网上发送。因为数据帧的 MAC 地址是选出的服务器，所以服务器肯定可以收到这个数据帧；
3. Real Server 接收到报文之后，发现报文的目标地址 VIP 是在本地的网络设备上，服务器处理这个报文，然后根据路由表将响应报文直接返回给客户。

![change-MAC](https://dn-simplecloud.qbox.me/1135081473148107079-wm)

在VS/DR中，根据缺省的TCP/IP协议栈处理，请求报文的目标地址为VIP，响应报文的源地址肯定也为VIP，所以响应报文不需要作任何修改，可以直接返回给客户，客户得到正常的服务，也不会知道是哪一台服务器处理的。

这便是 VS/DR 的处理数据包的整个过程，它有这样的一些特点：

- 集群节点，也就是 Real Server 与 Load Balacer 必须在同一个物理网络中
- RIP 通常是私有地址，也可以是公网地址，以便于远程管理与监控。
- Load Balancer 仅仅负责处理入站的请求，Real Server 将直接响应客户端
- 不支持端口映射：也就是Real Server 的端口必须是与 Load Balancer 对外服务的一样

使用 VS/DR 机制实现负载均衡，后端服务器支持数量可以超过百台

3.VS/TUN 实现虚拟服务器

VS/DR 限制 Real Server 与 Load Balancer 必须在同一个物理网络中，那若是分散在各地岂不是无法使用？所以有了 VS/TUN（Virtual Server via IP Tunneling）的诞生。

IP隧道（IP tunneling）是将一个 IP 报文封装在另一个 IP 报文的技术，这可以使得目标为一个 IP 地址的数据报文能被封装和转发到另一个 IP 地址。IP 隧道技术亦称为 IP 封装技术（IP encapsulation）。IP 隧道主要用于移动主机和虚拟私有网络（Virtual Private Network），在其中隧道都是静态建立的，隧道一端有一个 IP 地址，另一端也有唯一的 IP 地址。

我们利用 IP 隧道技术将请求报文封装转发给后端服务器，响应报文能从后端服务器直接返回给客户。但在这里，后端服务器有一组而非一个，所以我们不可能静态地建立一一对应的隧道，而是动态地选择 一台服务器，将请求报文封装和转发给选出的服务器。这样，我们可以利用 IP 隧道的原理将一组服务器上的网络服务组成在一个IP地址上的虚拟网络服务。 VS/TUN的体系结构如图所示，各个服务器将VIP地址配置在自己的IP隧道设备上。

![Tunnel-sturct](https://dn-simplecloud.qbox.me/1135081473147562052-wm)

它的连接调度和管理与 VS/NAT 中的一样，只是它的报文转发方法不同。调度器根据各个服务器的负载情况，动态地选择一台服务器， 将请求报文封装在另一个 IP 报文中，再将封装后的 IP 报文转发给选出的服务器；服务器收到报文后，先将报文解封获得原来目标地址为 VIP 的报文，服务器发现 VIP 地址被配置在本地的 IP 隧道设备上，所以就处理这个请求，然后根据路由表将响应报文直接返回给客户。

这便是 VS/TUN 的处理数据包的整个过程，它有这样的一些特点：

- 集群节点，也就是 Real Server 与 Load Balacer 可以跨越公网
- RIP 必须是公网地址。
- Load Balancer 仅仅负责处理入站的请求，Real Server 将直接响应客户端
- Real Server 的网关不能指向 Load Balancer
- 不支持端口映射：也就是Real Server 的端口必须是与 Load Balancer 对外服务的一样

这便是 LVS 所提供的 IP 负载均衡的三种技术，我们可以根据自己的情况做出不同的选择。

## 7. 实验总结

通过本节实验我们对负载均衡有了一个大体的了解，明白了

- 负载均衡的产生，也就是我们为什么会使用负载均衡
- 负载均衡的方式，了解使用负载均衡实现的方式与种类
- LVS 的特点，了解 LVS 的优势，选择 LVS 的理由
- LVS 的组成部分，了解 LVS 如何带来这样的优势
- LVS 的实现原理，了解 LVS 优势的根本原因

## 参考资料

[1]本文节选自章文嵩博士的 LVS 站点：<http://www.linuxvirtualserver.org/zh/lvs1.html#3>